{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d632363-23cb-484b-a7e7-5197da6ddc87",
   "metadata": {},
   "source": [
    "### Assignment 3: CNNs                                                                                          \n",
    "##### CSCI 536: Data Mining\n",
    "##### Huyen Nguyen and Jesse Hapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0444c8-3661-4d7b-a3e5-18f0657a0ce3",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing\n",
    "###### The goal for this portion of the assignment is to implement convolutional neural networks (CNNs) using PyTorch on the MNIST dataset. First,we import the core PyTorch libraries needed for building and training neural networks, as well as torchvision modules for accessing and transforming datasets. The `SummaryWriter` from `torch.utils.tensorboard` is initialized to log training statistics for visualization in TensorBoard, with logs stored in the directory `runs/mnist_cnn_base`. Next, the MNIST dataset is loaded using PyTorch’s built-in `datasets.MNIST API`. This dataset consists of 28×28 grayscale images of handwritten digits ranging from 0 to 9. A preprocessing pipeline is defined using `transforms.Compose`, which first converts the images to tensors and then normalizes them using the dataset’s **mean (0.1307)** and **standard deviation (0.3081)**. This normalization helps accelerate model convergence during training. Two data loaders are created: `train_loader` for batching and shuffling the training set, and `test_loader` for loading the test set without shuffling. A batch size of 64 is used for training and 1000 for evaluation to balance memory efficiency and computational throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4223b9e1-c725-4eee-8c49-284d455d30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for Microsoft GPU Support for non-CUDA/NVIDIA GPUs\n",
    "#import torch_directml\n",
    "#dml = torch_directml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0977e082-eeee-4f1d-b6e0-24e78a897bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for PyTorch and for data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "#Tensorboard import\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4067659-f5d1-4cab-90cf-29b22c3a4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard and save log file path\n",
    "writer = SummaryWriter(log_dir='runs/mnist_cnn_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da02570-03e3-451b-bf01-f3805d496862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load MNIST Data (10%) and preprocess MNIST dataset\n",
    "\n",
    "# Convert images to tensors and normalize using mean and std dev\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64e32b-84ec-423c-8c94-0a3aa817b567",
   "metadata": {},
   "source": [
    "### 2. CNN Model Architecture (Bonus: Batch Normalization and Max Pooling)\n",
    "###### The convolutional neural network (CNN) used in this project is implemented as a subclass of `nn.Module` and includes a convolutional feature extraction stack followed by a fully connected classification stack. The architecture satisfies the assignment's base requirement of **three convolutional layers** and **two fully connected layers**, and also incorporates the bonus portion of including **Batch Normalization** and **Max Pooling** in the CNN. The first convolutional layer transforms the 1-channel grayscale input into 32 feature maps, followed by batch normalization, ReLU activation, 2d max pooling to reduce the spatial dimensions to 14x14, followed by dropout to prevent overfitting. The second convolutional layer increases the depth to 64 channels and repeats the same sequence of operations, reducing the spatial size to 7×7. The third convolutional layer outputs 128 channels, followed by batch normalization, ReLU, and dropout without additional pooling. The fully connected stack then flattens the output and reduces it with a ReLU layer and dropout, and then maps to the final output layer with 10 neurons—one for each MNIST digit class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a769ab5-19ca-4d3c-9600-05cc727a4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Write CNN Model (40%) with 3 Conv Layers, Dropout, and 2 Fully Connected Layers\n",
    "# Bonus: Include Max_Pooling and Batch Normalization into CNN \n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            #Conv Layer 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(32),  #Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),     #Max_Pooling\n",
    "            nn.Dropout(0.25),    #Dropout\n",
    "\n",
    "            #Conv Layer 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),  #Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),     #Max_Pooling \n",
    "            nn.Dropout(0.25),    #Dropout\n",
    "\n",
    "            #Conv Layer 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128), #Batch Normalization  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.fc_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7335538-9aaf-4fb3-b9f6-88324a4616b2",
   "metadata": {},
   "source": [
    "### 3. Model Setup, Loss Function, and ADAM Optimizer\n",
    "###### To prepare the model for training, the script first checks whether a CUDA-capable GPU is available using `torch.cuda.is_available()`. If so, the model is moved to the GPU to accelerate training; otherwise, it runs on the CPU. This ensures the code is portable and can leverage available hardware. The loss function used is `CrossEntropyLoss`, which is appropriate for multi-class classification problems like MNIST, where the goal is to assign each input image to one of 10 possible digit classes (0 through 9). For optimization, the model uses the **ADAM optimizer** with a learning rate of *0.001*. ADAM is widely used due to its adaptive learning rate behavior and ability to converge efficiently, especially in deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcfdaf6-02c5-426e-b9ba-0c1d6b05a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 3a. Setup Device -- Move model to GPU if available\n",
    "#AMD DirectML Support for non-NVIDIA GPUs use either torch_DirectML or torch.device('cuda'...\n",
    "#device = torch_directml.device() \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MNIST_CNN().to(device)\n",
    "print(f\"Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e33059-cd13-43a7-be3e-b30efec53055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b. Define Loss Function (10%) and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()                        # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)     # ADAM Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550757c-861c-4f5f-8245-666ba6b56a66",
   "metadata": {},
   "source": [
    "### 4. Training and Testing Loops with TensorBoard Logging \n",
    "#### 4.1 Training Loop\n",
    "###### The training loop is defined in a function that takes the model, data loader, loss function, optimizer, and epoch number as input. It sets the model to training mode using model.train() and initializes a running total for the loss. For each batch of data, the images and labels are moved to the appropriate computation device (GPU or CPU). The model performs a forward pass to generate predictions, computes the loss using the criterion (CrossEntropyLoss), performs backpropagation with loss.backward(), and updates the weights via optimizer.step(). The batch loss is accumulated to calculate the average loss at the end of each epoch. Additionally, the loss from each batch is logged to TensorBoard using writer.add_scalar(\"Loss/train\", ...), where the global_step uniquely identifies each training iteration. Every 100 batches, the current loss is printed to the console for real-time monitoring. At the end of each epoch, the average loss is also logged to TensorBoard under the tag \"Loss/epoch_avg\" to help visualize the trend across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61efaf7b-4907-4bdb-8018-e6033be33a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train and Test Model (40%)\n",
    "\n",
    "# 4.1 Training loop\n",
    "def train(model, loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        global_step = epoch * len(loader) + batch_idx\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), global_step)  # Tensorboard log loss\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "           print(f\"Epoch {epoch+1}, Batch {batch_idx} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    writer.add_scalar(\"Loss/epoch_avg\", avg_loss, epoch)     # Tensorbaord log avg loss per epoch\n",
    "    print(f\"Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e98d4-7788-45a3-85de-7c67ecb27312",
   "metadata": {},
   "source": [
    "#### 4.2 Testing Loop\n",
    "###### The testing loop evaluates the model’s performance on the test dataset at the end of each epoch. The model is set to evaluation mode using `model.eval()`, which disables dropout and batch normalization updates to ensure consistent predictions. Gradient calculations are also disabled using `torch.no_grad()` to reduce memory usage and speed up computation. For each batch of test data, images and labels are moved to the appropriate device. The model makes predictions, and the class with the highest score for each image is selected using `torch.max()`. The number of correct predictions is accumulated across all batches to calculate the total accuracy. After the full test set is processed, accuracy is computed as a percentage and printed to the console. The result is also logged to **TensorBoard** under the tag `\"Accuracy/test\"` using `writer.add_scalar`, enabling performance visualization across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd8acdb2-8140-4006-b171-06b11376f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Testing loop\n",
    "def test(model, loader, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Accuracy logging setup\n",
    "    accuracy = 100 * correct / total\n",
    "    writer.add_scalar(\"Accuracy/test\", accuracy, epoch)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3480c2-6f73-4652-9596-71ee8059766e",
   "metadata": {},
   "source": [
    "### 5. Running Training and Evaluation \n",
    "###### The code executes the training and testing process across multiple epochs using a `for` loop. For each epoch, the model is first trained on the MNIST training dataset using the `train()` function, then evaluated on the test dataset using the `test()` function. This cycle repeats for a total of *5 epochs*, although the number can be adjusted as needed by modifying the `range(5)` statement. After the training and evaluation are complete, the **TensorBoard** `SummaryWriter` is properly closed using `writer.close()` to ensure that all logged metrics—such as training loss and test accuracy—are flushed to disk and available for visualization. This structure ensures that model performance improves iteratively while also capturing key metrics for analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51a5610e-6c4b-4d30-9c49-a0470e2ce5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0 - Loss: 2.3146\n",
      "Epoch 1, Batch 100 - Loss: 0.3607\n",
      "Epoch 1, Batch 200 - Loss: 0.2615\n",
      "Epoch 1, Batch 300 - Loss: 0.1910\n",
      "Epoch 1, Batch 400 - Loss: 0.0982\n",
      "Epoch 1, Batch 500 - Loss: 0.0920\n",
      "Epoch 1, Batch 600 - Loss: 0.0364\n",
      "Epoch 1, Batch 700 - Loss: 0.2402\n",
      "Epoch 1, Batch 800 - Loss: 0.0946\n",
      "Epoch 1, Batch 900 - Loss: 0.1115\n",
      "Epoch 1 Avg Loss: 0.1862\n",
      "Test Accuracy: 98.45%\n",
      "Epoch 2, Batch 0 - Loss: 0.0127\n",
      "Epoch 2, Batch 100 - Loss: 0.0599\n",
      "Epoch 2, Batch 200 - Loss: 0.0770\n",
      "Epoch 2, Batch 300 - Loss: 0.0606\n",
      "Epoch 2, Batch 400 - Loss: 0.0867\n",
      "Epoch 2, Batch 500 - Loss: 0.0855\n",
      "Epoch 2, Batch 600 - Loss: 0.0258\n",
      "Epoch 2, Batch 700 - Loss: 0.0756\n",
      "Epoch 2, Batch 800 - Loss: 0.0364\n",
      "Epoch 2, Batch 900 - Loss: 0.1042\n",
      "Epoch 2 Avg Loss: 0.0876\n",
      "Test Accuracy: 98.84%\n",
      "Epoch 3, Batch 0 - Loss: 0.1534\n",
      "Epoch 3, Batch 100 - Loss: 0.0519\n",
      "Epoch 3, Batch 200 - Loss: 0.0320\n",
      "Epoch 3, Batch 300 - Loss: 0.1527\n",
      "Epoch 3, Batch 400 - Loss: 0.0414\n",
      "Epoch 3, Batch 500 - Loss: 0.0285\n",
      "Epoch 3, Batch 600 - Loss: 0.0094\n",
      "Epoch 3, Batch 700 - Loss: 0.0770\n",
      "Epoch 3, Batch 800 - Loss: 0.0562\n",
      "Epoch 3, Batch 900 - Loss: 0.0649\n",
      "Epoch 3 Avg Loss: 0.0672\n",
      "Test Accuracy: 99.17%\n",
      "Epoch 4, Batch 0 - Loss: 0.1067\n",
      "Epoch 4, Batch 100 - Loss: 0.0157\n",
      "Epoch 4, Batch 200 - Loss: 0.0053\n",
      "Epoch 4, Batch 300 - Loss: 0.0862\n",
      "Epoch 4, Batch 400 - Loss: 0.1071\n",
      "Epoch 4, Batch 500 - Loss: 0.2629\n",
      "Epoch 4, Batch 600 - Loss: 0.0455\n",
      "Epoch 4, Batch 700 - Loss: 0.1675\n",
      "Epoch 4, Batch 800 - Loss: 0.0182\n",
      "Epoch 4, Batch 900 - Loss: 0.0173\n",
      "Epoch 4 Avg Loss: 0.0596\n",
      "Test Accuracy: 99.06%\n",
      "Epoch 5, Batch 0 - Loss: 0.0586\n",
      "Epoch 5, Batch 100 - Loss: 0.0108\n",
      "Epoch 5, Batch 200 - Loss: 0.0458\n",
      "Epoch 5, Batch 300 - Loss: 0.0072\n",
      "Epoch 5, Batch 400 - Loss: 0.0144\n",
      "Epoch 5, Batch 500 - Loss: 0.0801\n",
      "Epoch 5, Batch 600 - Loss: 0.0221\n",
      "Epoch 5, Batch 700 - Loss: 0.0165\n",
      "Epoch 5, Batch 800 - Loss: 0.0090\n",
      "Epoch 5, Batch 900 - Loss: 0.0477\n",
      "Epoch 5 Avg Loss: 0.0513\n",
      "Test Accuracy: 99.27%\n"
     ]
    }
   ],
   "source": [
    "# 5. Run training and testing\n",
    "for epoch in range(5): # change number of epochs if necessary for more or less training\n",
    "    train(model, train_loader, criterion, optimizer, epoch)\n",
    "    test(model, test_loader, epoch)\n",
    "\n",
    "# Closes TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0662ecd-ee77-40a6-bab8-c72656ecedde",
   "metadata": {},
   "source": [
    "#### 5.1 MNIST Experiment Results and TensorBoard Scalar Plots \n",
    "###### The CNN model trained on the MNIST dataset showed strong convergence and generalization across 5 epochs. The training loss decreased from **0.1862** in epoch 1 to **0.0513** in epoch 5, while test accuracy improved steadily from **98.45%** to **99.27%**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11caca42-be4b-4290-ae14-6e9f7770c4fc",
   "metadata": {},
   "source": [
    "### 📈 MNIST CNN Scalar Plots\n",
    "![Training Loss](MNIST_TB_Results_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a7d5b-0676-449c-848c-3f53f7eb5361",
   "metadata": {},
   "source": [
    "### 6. ResNet-18 on CIFAR-100 (Bonus)\n",
    "#### 6.1 Model Setup and Pretrained Weights\n",
    "###### To implement this, we pretrained ResNet-18 model was imported from `torchvision.models`. The model was initialized using `weights=ResNet18_Weights.DEFAULT`, which loads the latest ImageNet-trained parameters. The final fully connected layer of ResNet-18 was modified to output 100 logits, corresponding to the 100 classes in the *CIFAR-100* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e153caff-6640-4029-9c6c-a3c8b4f418df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81cbb7a6-c4fb-4d54-b0ec-e5cd1e1072e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load ResNet-18 and modify the final layer\n",
    "# Load pretrained ResNet-18 with default ImageNet weights\n",
    "resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "resnet18.fc = nn.Linear(512, 100)  # for CIFAR-100\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1af64-8c2c-4863-8068-30e5cb02411f",
   "metadata": {},
   "source": [
    "#### 6.2 Transformations \n",
    "###### The CIFAR-100 dataset, which contains 60,000 color images of size 32×32 across 100 object classes, was loaded using torchvision.datasets.CIFAR100. Each image was normalized using the dataset-specific mean and standard deviation: mean=(0.5071, 0.4865, 0.4409) and std=(0.2673, 0.2564, 0.2762). The training and test sets were batched using PyTorch’s DataLoader, with a batch size of 128 for training and 100 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83cb8322-a13d-46a9-82c4-cd0777debfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 2. Load CIFAR-100 dataset\n",
    "transform_cifar = transforms.Compose([\n",
    "    transforms.Resize(224), #resize CIFAR-100 to match ResNet input in order to boost test accuracy\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762))  # CIFAR-100 mean/std\n",
    "])\n",
    "\n",
    "cifar_train = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_cifar)\n",
    "cifar_test = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_cifar)\n",
    "\n",
    "cifar_train_loader = DataLoader(cifar_train, batch_size=128, shuffle=True)\n",
    "cifar_test_loader = DataLoader(cifar_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00339fe1-63eb-43c5-a445-5e46705bd8b5",
   "metadata": {},
   "source": [
    "#### 6.3 Loss Function and Optimizer\n",
    "###### The model was trained using the ADAM optimizer with a learning rate of 0.001, and CrossEntropyLoss as the objective function. These settings are consistent with the base configuration used in the MNIST CNN model. Training and evaluation were logged using a separate TensorBoard writer (runs/cifar100_resnet18) to isolate CIFAR-specific metrics from the MNIST logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8db6dfb-c385-4764-862e-1fc8e1524788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Loss function and optimizer\n",
    "cifar_criterion = nn.CrossEntropyLoss()\n",
    "cifar_optimizer = optim.Adam(resnet18.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63de24e9-4558-4501-8138-7407c45f2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TensorBoard Writer for CIFAR-100\n",
    "cifar_writer = SummaryWriter(log_dir='runs/cifar100_resnet18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d1c8a-7349-4c65-918f-08456b057179",
   "metadata": {},
   "source": [
    "#### 6.4 Training Loop\n",
    "###### Each training epoch looped through the training data and performed a standard forward pass, loss computation, backward pass, and parameter update. Individual batch losses were logged to TensorBoard using the \"Loss/train\" tag, while epoch-level average loss was logged under \"Loss/epoch_avg\". This allows for real-time visualization of convergence behavior across training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b77e4b90-7457-47ae-8a4d-e27581d10e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train and test for CIFAR-100\n",
    "def train_cifar(model, loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        global_step = epoch * len(loader) + batch_idx\n",
    "        cifar_writer.add_scalar(\"Loss/train\", loss.item(), global_step)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    cifar_writer.add_scalar(\"Loss/epoch_avg\", avg_loss, epoch)\n",
    "    print(f\"[CIFAR] Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "def test_cifar(model, loader, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = 100 * correct / total\n",
    "    cifar_writer.add_scalar(\"Accuracy/test\", acc, epoch)\n",
    "    print(f\"[CIFAR] Test Accuracy: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea3a71-e66e-424d-a28c-5e6d4fa5778a",
   "metadata": {},
   "source": [
    "#### 6.5 Testing Loop\n",
    "###### At the end of each epoch, the model was evaluated on the test set using the `test_cifar()` function. The accuracy was calculated by comparing predicted class labels with the true labels and was logged to TensorBoard under the `\"Accuracy/test\"` tag. A conditional print statement highlighted when accuracy surpassed the 70% threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cef5e5e7-9df2-42b2-b326-d98881473bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CIFAR] Epoch 1 Avg Loss: 1.7435\n",
      "[CIFAR] Test Accuracy: 60.48%\n",
      "[CIFAR] Epoch 2 Avg Loss: 0.9929\n",
      "[CIFAR] Test Accuracy: 65.13%\n",
      "[CIFAR] Epoch 3 Avg Loss: 0.6672\n",
      "[CIFAR] Test Accuracy: 66.29%\n",
      "[CIFAR] Epoch 4 Avg Loss: 0.4260\n",
      "[CIFAR] Test Accuracy: 66.92%\n",
      "[CIFAR] Epoch 5 Avg Loss: 0.2832\n",
      "[CIFAR] Test Accuracy: 66.54%\n",
      "[CIFAR] Epoch 6 Avg Loss: 0.1904\n",
      "[CIFAR] Test Accuracy: 69.22%\n",
      "[CIFAR] Epoch 7 Avg Loss: 0.1570\n",
      "[CIFAR] Test Accuracy: 68.06%\n",
      "[CIFAR] Epoch 8 Avg Loss: 0.1505\n",
      "[CIFAR] Test Accuracy: 66.51%\n",
      "[CIFAR] Epoch 9 Avg Loss: 0.1325\n",
      "[CIFAR] Test Accuracy: 66.97%\n",
      "[CIFAR] Epoch 10 Avg Loss: 0.1255\n",
      "[CIFAR] Test Accuracy: 68.03%\n",
      "[CIFAR] Epoch 11 Avg Loss: 0.1164\n",
      "[CIFAR] Test Accuracy: 68.73%\n",
      "[CIFAR] Epoch 12 Avg Loss: 0.0940\n",
      "[CIFAR] Test Accuracy: 68.17%\n",
      "[CIFAR] Epoch 13 Avg Loss: 0.0923\n",
      "[CIFAR] Test Accuracy: 67.81%\n",
      "[CIFAR] Epoch 14 Avg Loss: 0.0791\n",
      "[CIFAR] Test Accuracy: 67.91%\n",
      "[CIFAR] Epoch 15 Avg Loss: 0.0811\n",
      "[CIFAR] Test Accuracy: 66.34%\n",
      "[CIFAR] Epoch 16 Avg Loss: 0.0778\n",
      "[CIFAR] Test Accuracy: 68.08%\n",
      "[CIFAR] Epoch 17 Avg Loss: 0.0771\n",
      "[CIFAR] Test Accuracy: 68.20%\n",
      "[CIFAR] Epoch 18 Avg Loss: 0.0779\n",
      "[CIFAR] Test Accuracy: 67.60%\n",
      "[CIFAR] Epoch 19 Avg Loss: 0.0749\n",
      "[CIFAR] Test Accuracy: 68.39%\n",
      "[CIFAR] Epoch 20 Avg Loss: 0.0624\n",
      "[CIFAR] Test Accuracy: 68.32%\n",
      "[CIFAR] Epoch 21 Avg Loss: 0.0573\n",
      "[CIFAR] Test Accuracy: 67.67%\n",
      "[CIFAR] Epoch 22 Avg Loss: 0.0605\n",
      "[CIFAR] Test Accuracy: 66.98%\n",
      "[CIFAR] Epoch 23 Avg Loss: 0.0781\n",
      "[CIFAR] Test Accuracy: 67.95%\n",
      "[CIFAR] Epoch 24 Avg Loss: 0.0481\n",
      "[CIFAR] Test Accuracy: 70.09%\n",
      "70%+ Accuracy Achieved 70.09% at epoch 24\n",
      "[CIFAR] Epoch 25 Avg Loss: 0.0447\n",
      "[CIFAR] Test Accuracy: 67.25%\n"
     ]
    }
   ],
   "source": [
    "# 6. Run training + testing loop\n",
    "for epoch in range(25):  # May need 20+ epochs to hit 70%\n",
    "    train_cifar(resnet18, cifar_train_loader, cifar_criterion, cifar_optimizer, epoch)\n",
    "    acc = test_cifar(resnet18, cifar_test_loader, epoch)\n",
    "    if acc >= 70:\n",
    "        print(f\"70%+ Accuracy Achieved {acc:.2f}% at epoch {epoch+1}\")\n",
    "\n",
    "cifar_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c27d9a-372a-4ae9-aeb1-fd0860089fc2",
   "metadata": {},
   "source": [
    "#### 6.6 CIFAR-100 Experiment Results and TensorBoard Scalar Plots\n",
    "###### The ResNet-18 model was successfully trained on the CIFAR-100 dataset with a modified fully connected output layer (`Linear(512, 100)`) and pretrained ImageNet weights (`ResNet18_Weights.DEFAULT`). CIFAR-100 images were resized to 224×224 to match ResNet-18’s expected input dimensions. The model was trained using the ADAM optimizer with a learning rate of 0.001 and evaluated across **25 epochs**. The training process was monitored using TensorBoard, and the model achieved a peak test accuracy of **70.09%** at epoch 24."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af994d-1e69-47b8-a985-9a28ac078b02",
   "metadata": {},
   "source": [
    "### 📈 CIFAR-100 ResNet-18 Scalar Plots\n",
    "![Training Loss](CIFAR_TB_Results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604e214-a2fc-4084-8e63-1d35916ed28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytdml]",
   "language": "python",
   "name": "conda-env-pytdml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
